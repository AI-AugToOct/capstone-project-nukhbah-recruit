{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lxHi7uN_8qF2",
        "outputId": "5de87c5f-787c-4571-9acb-29ed0a252dc1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BsJHe52zC1iO",
        "outputId": "b61e71d2-8819-4daf-893d-d6478ab9b141"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: qwen_vl_utils in /usr/local/lib/python3.12/dist-packages (0.0.14)\n",
            "Requirement already satisfied: av in /usr/local/lib/python3.12/dist-packages (from qwen_vl_utils) (15.1.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from qwen_vl_utils) (25.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (from qwen_vl_utils) (11.3.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from qwen_vl_utils) (2.32.4)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->qwen_vl_utils) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->qwen_vl_utils) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->qwen_vl_utils) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->qwen_vl_utils) (2025.8.3)\n",
            "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.23.0+cu126)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.0)\n",
            "Requirement already satisfied: pdf2image in /usr/local/lib/python3.12/dist-packages (1.17.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (11.3.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.19.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.35.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.10)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.8.3)\n",
            "Found existing installation: bitsandbytes 0.41.1\n",
            "Uninstalling bitsandbytes-0.41.1:\n",
            "  Successfully uninstalled bitsandbytes-0.41.1\n",
            "Collecting bitsandbytes==0.41.1\n",
            "  Using cached bitsandbytes-0.41.1-py3-none-any.whl.metadata (9.8 kB)\n",
            "Using cached bitsandbytes-0.41.1-py3-none-any.whl (92.6 MB)\n",
            "Installing collected packages: bitsandbytes\n",
            "Successfully installed bitsandbytes-0.41.1\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.10.1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.0)\n",
            "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.12/dist-packages (from accelerate) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (25.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from accelerate) (6.0.2)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (2.8.0+cu126)\n",
            "Requirement already satisfied: huggingface_hub>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (0.35.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from accelerate) (0.6.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.19.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (1.1.10)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.4.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.8.3)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install qwen_vl_utils\n",
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "!pip install transformers pdf2image pillow pandas tqdm\n",
        "!pip uninstall bitsandbytes -y\n",
        "!pip install bitsandbytes==0.41.1 --no-deps\n",
        "!pip install accelerate transformers --upgrade\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "LrbK3Ooet6mq"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
        "\n",
        "import gc\n",
        "import torch\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "from transformers import Qwen2VLForConditionalGeneration, AutoProcessor\n",
        "from qwen_vl_utils import process_vision_info\n",
        "from pdf2image import convert_from_path\n",
        "from PIL import Image\n",
        "import json\n",
        "from pathlib import Path\n",
        "from typing import Dict, List, Optional\n",
        "from datetime import datetime\n",
        "import re\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "class PreciseCVExtractor:\n",
        "    def __init__(self, model_name: str = \"Qwen/Qwen2-VL-7B-Instruct\"):\n",
        "        print(\"=\"*60)\n",
        "        print(\" Loading Precise CV Extractor\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        gc.collect()\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.empty_cache()\n",
        "            torch.cuda.synchronize()\n",
        "\n",
        "            gpu_name = torch.cuda.get_device_name(0)\n",
        "            gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
        "            free_memory = torch.cuda.mem_get_info()[0] / 1e9\n",
        "            print(f\"GPU: {gpu_name} ({gpu_memory:.1f} GB)\")\n",
        "            print(f\"Free Memory: {free_memory:.1f} GB\")\n",
        "\n",
        "        print(f\"Loading 7B model...\")\n",
        "\n",
        "        try:\n",
        "            self.model = Qwen2VLForConditionalGeneration.from_pretrained(\n",
        "                model_name,\n",
        "                torch_dtype=torch.float16,\n",
        "                device_map=\"auto\",\n",
        "                trust_remote_code=True,\n",
        "                low_cpu_mem_usage=True,\n",
        "            )\n",
        "\n",
        "            self.model.eval()\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error: {e}\")\n",
        "            raise\n",
        "\n",
        "        self.processor = AutoProcessor.from_pretrained(model_name, trust_remote_code=True)\n",
        "        self.model_name = model_name\n",
        "\n",
        "        gc.collect()\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "        print(f\"✓ Model loaded!\")\n",
        "\n",
        "        self.output_dir = Path(\"extracted_cvs_precise\")\n",
        "        self.output_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    def create_strict_extraction_prompt(self) -> str:\n",
        "        return \"\"\"STRICT CV EXTRACTION - EXTRACT ONLY WHAT EXISTS\n",
        "\n",
        " CRITICAL RULES:\n",
        "1. Extract ONLY text that is VISIBLY WRITTEN in the CV\n",
        "2. NEVER invent or add dates that don't exist\n",
        "3. NEVER add job descriptions - read ALL bullet points completely\n",
        "4. If something doesn't exist → use null or []\n",
        "5. DO NOT mix technical skills with soft skills\n",
        "6. DO NOT include soft skills (leadership, communication, teamwork)\n",
        "\n",
        "═══════════════════════════════════════════════════════════\n",
        "\n",
        "{\n",
        "  \"personal_info\": {\n",
        "    \"name\": \"exact full name or null\",\n",
        "    \"job_title\": \"exact title or null\"\n",
        "  },\n",
        "  \"contact_info\": {\n",
        "    \"email\": \"exact email or null\",\n",
        "    \"phone\": \"exact phone or null\",\n",
        "    \"location\": \"exact location or null\",\n",
        "    \"linkedin\": \"exact URL or null\",\n",
        "    \"github\": \"exact URL or null\"\n",
        "  },\n",
        "  \"education\": [\n",
        "    {\n",
        "      \"degree\": \"exact degree name\",\n",
        "      \"field\": \"exact major/specialization\",\n",
        "      \"institution\": \"exact university name\",\n",
        "      \"start_date\": \"ONLY if written (2018 or Jan 2018) or null\",\n",
        "      \"end_date\": \"ONLY if written (2022 or Present) or null\"\n",
        "    }\n",
        "  ],\n",
        "  \"experience\": [\n",
        "    {\n",
        "      \"job_title\": \"exact job title\",\n",
        "      \"company\": \"exact company name\",\n",
        "      \"location\": \"exact location or null\",\n",
        "      \"start_date\": \"ONLY if written or null\",\n",
        "      \"end_date\": \"ONLY if written or null\",\n",
        "      \"responsibilities\": [\n",
        "        \"Read ALL bullet points COMPLETELY\",\n",
        "        \"Copy EACH bullet point EXACTLY\",\n",
        "        \"Do NOT summarize or shorten\",\n",
        "        \"Include EVERY responsibility listed\"\n",
        "      ]\n",
        "    }\n",
        "  ],\n",
        "  \"projects\": [\n",
        "    {\n",
        "      \"name\": \"exact project name\",\n",
        "      \"description\": \"exact full description\",\n",
        "      \"date\": \"ONLY if mentioned or null\"\n",
        "    }\n",
        "  ],\n",
        "  \"technical_skills\": [\n",
        "    \"ONLY from 'Skills' or 'Technical Skills' section\",\n",
        "    \"Do NOT extract from projects/experience\",\n",
        "    \"Do NOT include soft skills\",\n",
        "    \"Flat array, no categories\"\n",
        "  ],\n",
        "  \"certifications\": [\n",
        "    {\n",
        "      \"name\": \"exact name\",\n",
        "      \"issuer\": \"exact issuer or null\",\n",
        "      \"date\": \"ONLY if written or null\"\n",
        "    }\n",
        "  ],\n",
        "  \"languages\": [\n",
        "    {\n",
        "      \"language\": \"exact language\",\n",
        "      \"proficiency\": \"exact level\"\n",
        "    }\n",
        "  ]\n",
        "}\n",
        "\n",
        "═══════════════════════════════════════════════════════════\n",
        "\n",
        " DATES RULES:\n",
        "• No date visible → null\n",
        "• Only year → \"2020\"\n",
        "• Month + year → \"Jan 2020\"\n",
        "• NEVER guess dates\n",
        "• Use \"Present\" ONLY if written\n",
        "\n",
        " SKILLS RULES:\n",
        "• Extract ONLY from labeled skills section\n",
        "• IGNORE: leadership, communication, teamwork, problem-solving\n",
        "• Keep ONLY: Python, Java, AWS, Docker, etc.\n",
        "• One skill ONE time (no duplicates)\n",
        "\n",
        " RESPONSIBILITIES RULES:\n",
        "• Read the COMPLETE job description\n",
        "• Copy EVERY bullet point EXACTLY\n",
        "• Do NOT skip any points\n",
        "• Do NOT paraphrase\n",
        "\n",
        "REMEMBER: Extract ONLY what you can SEE. Nothing more.\"\"\"\n",
        "\n",
        "    def pdf_to_images(self, pdf_path: str, dpi: int = 200) -> List[Image.Image]:\n",
        "        return convert_from_path(pdf_path, dpi=dpi)\n",
        "\n",
        "    def extract_from_image(self, image: Image.Image, page_num: int = 1) -> Dict:\n",
        "        try:\n",
        "            max_size = 1024\n",
        "            if max(image.size) > max_size:\n",
        "                ratio = max_size / max(image.size)\n",
        "                new_size = tuple(int(dim * ratio) for dim in image.size)\n",
        "                image = image.resize(new_size, Image.Resampling.LANCZOS)\n",
        "\n",
        "            messages = [{\n",
        "                \"role\": \"user\",\n",
        "                \"content\": [\n",
        "                    {\"type\": \"image\", \"image\": image},\n",
        "                    {\"type\": \"text\", \"text\": self.create_strict_extraction_prompt()}\n",
        "                ]\n",
        "            }]\n",
        "\n",
        "            text = self.processor.apply_chat_template(\n",
        "                messages,\n",
        "                tokenize=False,\n",
        "                add_generation_prompt=True\n",
        "            )\n",
        "            image_inputs, video_inputs = process_vision_info(messages)\n",
        "            inputs = self.processor(\n",
        "                text=[text],\n",
        "                images=image_inputs,\n",
        "                videos=video_inputs,\n",
        "                padding=True,\n",
        "                return_tensors=\"pt\"\n",
        "            )\n",
        "            inputs = inputs.to(self.model.device)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                generated_ids = self.model.generate(\n",
        "                    **inputs,\n",
        "                    max_new_tokens=2000,\n",
        "                    temperature=0.2,\n",
        "                    do_sample=True,\n",
        "                    top_p=0.95,\n",
        "                    repetition_penalty=1.1\n",
        "                )\n",
        "\n",
        "            generated_ids_trimmed = [\n",
        "                out_ids[len(in_ids):]\n",
        "                for in_ids, out_ids in zip(inputs.input_ids, generated_ids)\n",
        "            ]\n",
        "            output_text = self.processor.batch_decode(\n",
        "                generated_ids_trimmed,\n",
        "                skip_special_tokens=True,\n",
        "                clean_up_tokenization_spaces=False\n",
        "            )[0]\n",
        "\n",
        "            del inputs, generated_ids, generated_ids_trimmed, image_inputs, video_inputs\n",
        "            gc.collect()\n",
        "            if torch.cuda.is_available():\n",
        "                torch.cuda.empty_cache()\n",
        "                torch.cuda.synchronize()\n",
        "\n",
        "            result = self.parse_and_clean_json(output_text)\n",
        "            return result\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"✗ Error: {str(e)[:100]}\")\n",
        "            gc.collect()\n",
        "            if torch.cuda.is_available():\n",
        "                torch.cuda.empty_cache()\n",
        "            return {}\n",
        "\n",
        "    def parse_and_clean_json(self, output_text: str) -> Dict:\n",
        "        try:\n",
        "            if \"```json\" in output_text:\n",
        "                json_text = output_text.split(\"```json\")[1].split(\"```\")[0]\n",
        "            elif \"```\" in output_text:\n",
        "                json_text = output_text.split(\"```\")[1].split(\"```\")[0]\n",
        "            else:\n",
        "                json_text = output_text\n",
        "\n",
        "            json_text = json_text.strip()\n",
        "\n",
        "            start_idx = json_text.find(\"{\")\n",
        "            end_idx = json_text.rfind(\"}\") + 1\n",
        "            if start_idx != -1 and end_idx > start_idx:\n",
        "                json_text = json_text[start_idx:end_idx]\n",
        "\n",
        "            json_text = re.sub(r',\\s*}', '}', json_text)\n",
        "            json_text = re.sub(r',\\s*]', ']', json_text)\n",
        "\n",
        "            data = json.loads(json_text)\n",
        "            data = self.clean_extracted_data(data)\n",
        "\n",
        "            return data\n",
        "\n",
        "        except json.JSONDecodeError:\n",
        "            return {}\n",
        "\n",
        "    def clean_extracted_data(self, data: Dict) -> Dict:\n",
        "        if not data:\n",
        "            return data\n",
        "\n",
        "        soft_skills = [\n",
        "            'leadership', 'communication', 'teamwork', 'problem-solving',\n",
        "            'problem solving', 'critical thinking', 'time management',\n",
        "            'collaboration', 'adaptability', 'creativity', 'analytical',\n",
        "\n",
        "        ]\n",
        "\n",
        "        if 'technical_skills' in data:\n",
        "            if isinstance(data['technical_skills'], list):\n",
        "                seen = set()\n",
        "                unique_skills = []\n",
        "                for skill in data['technical_skills']:\n",
        "                    if skill and skill.lower() not in [s.lower() for s in soft_skills]:\n",
        "                        if skill.lower() not in seen:\n",
        "                            seen.add(skill.lower())\n",
        "                            unique_skills.append(skill)\n",
        "                data['technical_skills'] = unique_skills\n",
        "            elif isinstance(data['technical_skills'], dict):\n",
        "                all_skills = []\n",
        "                for category, skills in data['technical_skills'].items():\n",
        "                    if isinstance(skills, list):\n",
        "                        all_skills.extend(skills)\n",
        "                seen = set()\n",
        "                unique_skills = []\n",
        "                for skill in all_skills:\n",
        "                    if skill and skill.lower() not in [s.lower() for s in soft_skills]:\n",
        "                        if skill.lower() not in seen:\n",
        "                            seen.add(skill.lower())\n",
        "                            unique_skills.append(skill)\n",
        "                data['technical_skills'] = unique_skills\n",
        "\n",
        "        if 'soft_skills' in data:\n",
        "            del data['soft_skills']\n",
        "\n",
        "        if 'projects' in data and isinstance(data['projects'], list):\n",
        "            for project in data['projects']:\n",
        "                if isinstance(project, dict):\n",
        "                    empty_fields = [k for k, v in project.items()\n",
        "                                   if v is None or v == \"\" or v == []]\n",
        "                    for field in empty_fields:\n",
        "                        del project[field]\n",
        "\n",
        "        if 'education' in data and isinstance(data['education'], list):\n",
        "            for edu in data['education']:\n",
        "                if isinstance(edu, dict):\n",
        "                    empty_fields = [k for k, v in edu.items()\n",
        "                                   if v is None or v == \"\"]\n",
        "                    for field in empty_fields:\n",
        "                        del edu[field]\n",
        "\n",
        "        if 'experience' in data and isinstance(data['experience'], list):\n",
        "            for exp in data['experience']:\n",
        "                if isinstance(exp, dict):\n",
        "                    empty_fields = [k for k, v in exp.items()\n",
        "                                   if v is None or v == \"\" or (isinstance(v, list) and len(v) == 0)]\n",
        "                    for field in empty_fields:\n",
        "                        if field != 'responsibilities':\n",
        "                            del exp[field]\n",
        "\n",
        "                    if 'responsibilities' in exp and isinstance(exp['responsibilities'], list):\n",
        "                        exp['responsibilities'] = list(dict.fromkeys(exp['responsibilities']))\n",
        "\n",
        "        return data\n",
        "\n",
        "    def merge_pages_carefully(self, pages: List[Dict]) -> Dict:\n",
        "        if not pages:\n",
        "            return {}\n",
        "        if len(pages) == 1:\n",
        "            return pages[0]\n",
        "\n",
        "        merged = pages[0].copy() if pages[0] else {}\n",
        "\n",
        "        for page in pages[1:]:\n",
        "            if not page:\n",
        "                continue\n",
        "\n",
        "            for field in ['personal_info', 'contact_info']:\n",
        "                if field in page and isinstance(page[field], dict):\n",
        "                    if field not in merged:\n",
        "                        merged[field] = {}\n",
        "                    for key, value in page[field].items():\n",
        "                        if value and (key not in merged[field] or not merged[field][key]):\n",
        "                            merged[field][key] = value\n",
        "\n",
        "            list_fields = ['education', 'experience', 'projects', 'certifications', 'languages']\n",
        "            for field in list_fields:\n",
        "                if field in page and isinstance(page[field], list):\n",
        "                    if field not in merged:\n",
        "                        merged[field] = []\n",
        "\n",
        "                    for item in page[field]:\n",
        "                        is_duplicate = False\n",
        "\n",
        "                        if isinstance(item, dict):\n",
        "                            for existing in merged[field]:\n",
        "                                if isinstance(existing, dict):\n",
        "                                    if field == 'education':\n",
        "                                        if (item.get('degree') == existing.get('degree') and\n",
        "                                            item.get('institution') == existing.get('institution')):\n",
        "                                            is_duplicate = True\n",
        "                                            break\n",
        "                                    elif field == 'experience':\n",
        "                                        if (item.get('job_title') == existing.get('job_title') and\n",
        "                                            item.get('company') == existing.get('company')):\n",
        "                                            is_duplicate = True\n",
        "                                            break\n",
        "                                    elif field == 'projects':\n",
        "                                        if item.get('name') == existing.get('name'):\n",
        "                                            is_duplicate = True\n",
        "                                            break\n",
        "                        else:\n",
        "                            if item in merged[field]:\n",
        "                                is_duplicate = True\n",
        "\n",
        "                        if not is_duplicate:\n",
        "                            merged[field].append(item)\n",
        "\n",
        "            if 'technical_skills' in page:\n",
        "                if 'technical_skills' not in merged:\n",
        "                    merged['technical_skills'] = []\n",
        "\n",
        "                if isinstance(page['technical_skills'], list):\n",
        "                    for skill in page['technical_skills']:\n",
        "                        if skill and skill not in merged['technical_skills']:\n",
        "                            merged['technical_skills'].append(skill)\n",
        "\n",
        "        merged = self.clean_extracted_data(merged)\n",
        "        return merged\n",
        "\n",
        "    def extract_single_cv(self, pdf_path: Path) -> Dict:\n",
        "        try:\n",
        "            print(f\"\\n📄 {pdf_path.name}\")\n",
        "\n",
        "            images = self.pdf_to_images(str(pdf_path))\n",
        "            print(f\"   Pages: {len(images)}\")\n",
        "\n",
        "            all_page_data = []\n",
        "\n",
        "            for idx, image in enumerate(images, 1):\n",
        "                print(f\"   [{idx}/{len(images)}]\", end=\" \", flush=True)\n",
        "\n",
        "                page_data = self.extract_from_image(image, page_num=idx)\n",
        "\n",
        "                if page_data:\n",
        "                    all_page_data.append(page_data)\n",
        "\n",
        "                del image\n",
        "                gc.collect()\n",
        "                if torch.cuda.is_available():\n",
        "                    torch.cuda.empty_cache()\n",
        "\n",
        "            print(\"✓\")\n",
        "\n",
        "            if not all_page_data:\n",
        "                return {}\n",
        "\n",
        "            final_data = self.merge_pages_carefully(all_page_data)\n",
        "\n",
        "            final_data['_metadata'] = {\n",
        "                'source_file': pdf_path.name,\n",
        "                'total_pages': len(images),\n",
        "                'extraction_timestamp': datetime.now().isoformat()\n",
        "            }\n",
        "\n",
        "            json_path = self.output_dir / f\"{pdf_path.stem}.json\"\n",
        "            with open(json_path, 'w', encoding='utf-8') as f:\n",
        "                json.dump(final_data, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "            name = final_data.get('personal_info', {}).get('name', 'N/A')\n",
        "            skills_count = len(final_data.get('technical_skills', []))\n",
        "            print(f\"   ✓ {name} | Skills: {skills_count}\")\n",
        "\n",
        "            del all_page_data, images\n",
        "            gc.collect()\n",
        "\n",
        "            return final_data\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"   ✗ Error: {str(e)[:100]}\")\n",
        "            return {}\n",
        "\n",
        "    def extract_batch(self, input_path: str, max_files: Optional[int] = None) -> Dict:\n",
        "        path = Path(input_path)\n",
        "\n",
        "        if not path.exists():\n",
        "            raise FileNotFoundError(f\"Path not found: {input_path}\")\n",
        "\n",
        "        if path.is_file() and path.suffix.lower() == '.pdf':\n",
        "            pdf_files = [path]\n",
        "        elif path.is_dir():\n",
        "            pdf_files = sorted(list(path.glob(\"*.pdf\")))\n",
        "            if max_files:\n",
        "                pdf_files = pdf_files[:max_files]\n",
        "        else:\n",
        "            raise ValueError(f\"Invalid path: must be a PDF file or directory\")\n",
        "\n",
        "        if not pdf_files:\n",
        "            return {\"total\": 0, \"successful\": 0, \"failed\": 0, \"data\": []}\n",
        "\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\" CV EXTRACTION\")\n",
        "        print(\"=\"*60)\n",
        "        print(f\"Files: {len(pdf_files)}\")\n",
        "        print(f\"Output: {self.output_dir.absolute()}\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        all_results = []\n",
        "        successful = 0\n",
        "        failed_files = []\n",
        "\n",
        "        for i, pdf_file in enumerate(pdf_files, 1):\n",
        "            print(f\"\\n[{i}/{len(pdf_files)}]\", end=\" \")\n",
        "\n",
        "            result = self.extract_single_cv(pdf_file)\n",
        "\n",
        "            if result and result.get('personal_info'):\n",
        "                all_results.append(result)\n",
        "                successful += 1\n",
        "            else:\n",
        "                failed_files.append(pdf_file.name)\n",
        "\n",
        "            gc.collect()\n",
        "            if torch.cuda.is_available():\n",
        "                torch.cuda.empty_cache()\n",
        "\n",
        "        if all_results:\n",
        "            combined_json_path = self.output_dir / \"all_cvs_combined.json\"\n",
        "            with open(combined_json_path, 'w', encoding='utf-8') as f:\n",
        "                json.dump(all_results, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(f\" SUCCESS: {successful}/{len(pdf_files)}\")\n",
        "        print(f\" FAILED: {len(failed_files)}\")\n",
        "        print(f\" Output: {self.output_dir.absolute()}/\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        if failed_files:\n",
        "            print(f\"\\n✗ Failed files:\")\n",
        "            for file in failed_files[:5]:\n",
        "                print(f\"  - {file}\")\n",
        "\n",
        "        return {\n",
        "            \"total\": len(pdf_files),\n",
        "            \"successful\": successful,\n",
        "            \"failed\": len(pdf_files) - successful,\n",
        "            \"data\": all_results,\n",
        "            \"failed_files\": failed_files\n",
        "        }\n",
        "\n"
      ],
      "metadata": {
        "id": "M1B-CiMicRHY"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "36410d4496274401ad2f9302bcfb1e01",
            "075b7888be204c30bd5153962f7efa58",
            "2b227d914a674ed7b51fb25726b9d3bb",
            "41358c4e3c5546e7ba459fcccf4af5ef",
            "5fd46cc96f2f424ab861f28efe10ccf4",
            "551daa8ebd4346178f4312ea0b7b5d8a",
            "8826e56c4db2450f923bc7abd18ececd",
            "d5555f3f139040fead642ec7ce2c8c26",
            "0128d33ff75a40b697baff5b46f59bf2",
            "725acd21b1174001a324d7504f1d82f5",
            "3bc1a6eeee384b728f10bd4669b8092a"
          ]
        },
        "id": "LJLnS0u90HAy",
        "outputId": "da1eeaae-5b95-4b1d-8357-841e165dfd7b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            " Starting Precise CV Extraction\n",
            "============================================================\n",
            "============================================================\n",
            " Loading Precise CV Extractor\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`torch_dtype` is deprecated! Use `dtype` instead!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU: Tesla T4 (15.8 GB)\n",
            "Free Memory: 15.7 GB\n",
            "Loading 7B model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "36410d4496274401ad2f9302bcfb1e01"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:accelerate.big_modeling:Some parameters are on the meta device because they were offloaded to the cpu.\n",
            "The image processor of type `Qwen2VLImageProcessor` is now loaded as a fast processor by default, even if the model checkpoint was saved with a slow processor. This is a breaking change and may produce slightly different outputs. To continue using the slow processor, instantiate this class with `use_fast=False`. Note that this behavior will be extended to all models in a future release.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Model loaded!\n",
            "\n",
            "============================================================\n",
            " CV EXTRACTION\n",
            "============================================================\n",
            "Files: 3\n",
            "Output: /content/extracted_cvs_precise\n",
            "============================================================\n",
            "\n",
            "[1/3] \n",
            "📄 Aljwharah Almousa cv RUH(4).pdf\n",
            "   Pages: 1\n",
            "   [1/1] ✓\n",
            "   ✓ ALJUHARAH ALMOUSA | Skills: 20\n",
            "\n",
            "[2/3] \n",
            "📄 Document (7).pdf\n",
            "   Pages: 1\n",
            "   [1/1] ✓\n",
            "   ✓ Ali | Skills: 23\n",
            "\n",
            "[3/3] \n",
            "📄 resume_data_analyst.pdf\n",
            "   Pages: 1\n",
            "   [1/1] ✓\n",
            "   ✓ Sara Al-Harbi | Skills: 7\n",
            "\n",
            "============================================================\n",
            " SUCCESS: 3/3\n",
            " FAILED: 0\n",
            " Output: /content/extracted_cvs_precise/\n",
            "============================================================\n",
            "\n",
            "Process completed!\n",
            "Check results at: extracted_cvs_precise/\n",
            "\n",
            "Successfully processed 3 CVs\n",
            "Files created:\n",
            "  - Individual JSON for each CV\n",
            "  - all_cvs_combined.json (all CVs in one file)\n"
          ]
        }
      ],
      "source": [
        "CV_FOLDER = \"/content/drive/MyDrive/cvs\"\n",
        "MAX_FILES = 5\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\" Starting Precise CV Extraction\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "extractor = PreciseCVExtractor()\n",
        "\n",
        "results = extractor.extract_batch(CV_FOLDER, max_files=MAX_FILES)\n",
        "\n",
        "print(\"\\nProcess completed!\")\n",
        "print(f\"Check results at: extracted_cvs_precise/\")\n",
        "\n",
        "if results['successful'] > 0:\n",
        "    print(f\"\\nSuccessfully processed {results['successful']} CVs\")\n",
        "    print(\"Files created:\")\n",
        "    print(\"  - Individual JSON for each CV\")\n",
        "    print(\"  - all_cvs_combined.json (all CVs in one file)\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "36410d4496274401ad2f9302bcfb1e01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_075b7888be204c30bd5153962f7efa58",
              "IPY_MODEL_2b227d914a674ed7b51fb25726b9d3bb",
              "IPY_MODEL_41358c4e3c5546e7ba459fcccf4af5ef"
            ],
            "layout": "IPY_MODEL_5fd46cc96f2f424ab861f28efe10ccf4"
          }
        },
        "075b7888be204c30bd5153962f7efa58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_551daa8ebd4346178f4312ea0b7b5d8a",
            "placeholder": "​",
            "style": "IPY_MODEL_8826e56c4db2450f923bc7abd18ececd",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "2b227d914a674ed7b51fb25726b9d3bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d5555f3f139040fead642ec7ce2c8c26",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0128d33ff75a40b697baff5b46f59bf2",
            "value": 5
          }
        },
        "41358c4e3c5546e7ba459fcccf4af5ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_725acd21b1174001a324d7504f1d82f5",
            "placeholder": "​",
            "style": "IPY_MODEL_3bc1a6eeee384b728f10bd4669b8092a",
            "value": " 5/5 [01:21&lt;00:00, 13.53s/it]"
          }
        },
        "5fd46cc96f2f424ab861f28efe10ccf4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "551daa8ebd4346178f4312ea0b7b5d8a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8826e56c4db2450f923bc7abd18ececd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d5555f3f139040fead642ec7ce2c8c26": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0128d33ff75a40b697baff5b46f59bf2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "725acd21b1174001a324d7504f1d82f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3bc1a6eeee384b728f10bd4669b8092a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}